import pandas as pd
import numpy as np
from scipy.stats import boxcox
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV
from sklearn.metrics import mean_squared_error, r2_score


# âœ… Carregamento do csv  ================================
database = pd.read_csv("winequality-red.csv", sep=";")
print("\nDimensÃµes do conjunto completo: ", database.shape)
# =======================================================



# âœ… Shuffle ================================================================
ind_shuffle = np.random.permutation(len(database))          #cria os indicies
database = database.iloc[ind_shuffle].reset_index(drop=True)#embaralha
# ==========================================================================



# âœ… SeparaÃ§Ã£o de features e target ========================================
x_database = database.drop(columns=["quality"])
y_database = database["quality"]
# ==========================================================================



# âœ… CÃ¡lculo do Skewness pra ajeitar =======================================
skew = x_database.skew()
# ==========================================================================



# âœ… SeparaÃ§Ã£o treino e teste ==============================================
n = int(np.floor(len(database)/3))
data_train = database[:2*n]
data_test = database[2*n:]

y_train = y_database[:2*n]
x_train = x_database[:2*n]
y_test = y_database[2*n:]
x_test = x_database[2*n:]

#print("\nDimensÃµes dos preditores de treino: ", x_train.shape)
#print("\nDimensÃµes dos preditores de teste: ", x_test.shape)
# ==========================================================================



# âœ… Ajuste Box-Cox =========================================================
x_train_ajusted = x_train.copy()
lambdas = {}
shifts = {}
for col in x_train_ajusted.columns:
    val = x_train_ajusted[col].values
    if np.any(val <= 0):                # Garantir valores positivos (SHIFT)
        shift = abs(np.min(val)) + 1e-6
        val = val + shift
        shifts[col] = shift             # Guarda os SHIFT pra depois
    else:
        shifts[col] = 0.0

    transf_val, boxcox_lambda = boxcox(val)
    x_train_ajusted[col] = transf_val   
    lambdas[col] = boxcox_lambda        # Guarda os lambda pra depois
# ==========================================================================



# âœ… Z-Score para PCA =============================================================
mean_train = np.mean(x_train_ajusted, axis=0)  # Esses dois vao ser usados no teste
std_train = np.std(x_train_ajusted, axis=0)    # Pra Z-score de la
x_train_ajusted_norm = (x_train_ajusted - mean_train) / std_train
# =================================================================================



# âœ… PCA completo ===========================================================
pca = PCA()
pca.fit(x_train_ajusted_norm)

print("\nVariÃ¢ncia explicada cumulativa:")
print(pca.explained_variance_ratio_.cumsum())

n_pcs = 9       # Decidir de acordo com a % de VariÃ¢ncia explicada (97+)
pca_reduzido = PCA(n_components=n_pcs)
pca_reduzido.fit(x_train_ajusted_norm)

x_train_pca = pca_reduzido.transform(x_train_ajusted_norm)
print("\nDimensionalidade de treino transformado: ", x_train_pca.shape)
# ==========================================================================


#============================================= ğŸ¯ INICIO DA FASE DE TREINO ğŸ¯====================================================
# âœ… RegressÃ£o multivariada via MÃ­nimos quadrados (OLS) nativo do ScikitLearn ====================================================
ols = LinearRegression(fit_intercept=True)      # cria o objeto do tipo LinearRegression que por padrao Ã© OLS com o intercepto jÃ¡
ols.fit(x_train_pca, y_train)                   # aplica nos dados de treino apenas com o .fit


#===================== InformaÃ§Ãµes do modelo ===============================
#print("\nIntercepto:", ols.intercept_)          # B0 do modelo
#print("Betas:", ols.coef_)                      # 9 B's restantes do modelo
#===========================================================================


# AVALIAÃ‡ÃƒO DO TREINO
y_predict_train = ols.predict(x_train_pca)                          # obj.predict pega as prediÃ§Ãµes do modelo nos dados passados
rmse_train = np.sqrt(mean_squared_error(y_train, y_predict_train))  # Raiz do MSE nativo do Sktlearn.metrics
r2_train = r2_score(y_train, y_predict_train)                       # R2 nativo do Sktlearn.metrics

print("\nRMSE de treino do nÃ©todo nativo:", rmse_train)                     
print("R2 de treino do mÃ©todo nativo  :", r2_train)            
# ================================================================================================================================



#=============================================ğŸ§ª INICIO DA FASE DE TESTES ğŸ§ª=====================================================
# Box-Cox no teste ---------------------------------------------------------------------------------------------------------------
x_test_ajusted = x_test.copy()
for col in x_test.columns:
    val_test = x_test_ajusted[col].values + shifts[col]         # mesmo shift do treino
    x_test_ajusted[col] = boxcox(val_test, lmbda=lambdas[col])  # mesmo lambda do treino

# Z-score usando stats do TREINO -------------------------------------------------------------------------------------------------
x_test_ajusted_norm = (x_test_ajusted - mean_train) / std_train # Usar as metricas do Treino tbm no Z-score

# PCA usando modelo treinado -----------------------------------------------------------------------------------------------------
x_test_pca = pca_reduzido.transform(x_test_ajusted_norm)        # Usando o mesmo PCA desenvolvido no treino

# PrediÃ§Ã£o no teste --------------------------------------------------------------------------------------------------------------
y_predict_test = ols.predict(x_test_pca)                        # variavel que guarda prediÃ§Ãµes do modelo
rmse_test = np.sqrt(mean_squared_error(y_test, y_predict_test)) # calculo normal do RMSE com o MSE nativo Sktlearn.metrics
r2_test = r2_score(y_test, y_predict_test)                      # Nativo R2 do Sktlearn.metrics

# ================================================================================================================================

print("\nRMSE de teste do nÃ©todo nativo :", rmse_test)
print("R2 de teste do mÃ©todo nativo   :", r2_test)

# ================================================================================================================================
# (RIDGE E LASSO)
# ================================================================================================================================

print("\n" + "="*80)
print("INICIANDO A EGULARIZAÃ‡ÃƒO (RIDGE E LASSO)")
print("="*80)
# --- RIDGE REGRESSION (L2) ---
print("\n--- RIDGE REGRESSION (CV AutomÃ¡tico) ---")

# Testamos vÃ¡rios alphas (forÃ§a da penalidade)
alphas_range = np.logspace(-2, 2, 50) # De 0.01 a 100

# CV=5 garante a validaÃ§Ã£o cruzada que o Leo queria
ridge_model = RidgeCV(alphas=alphas_range, cv=5)
ridge_model.fit(x_train_ajusted_norm, y_train)

# PrevisÃ£o no Teste
y_pred_ridge = ridge_model.predict(x_test_ajusted_norm)

# MÃ©tricas
rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))
r2_ridge = r2_score(y_test, y_pred_ridge)

print(f"Melhor Alpha Ridge: {ridge_model.alpha_:.4f}")
print(f"RMSE Ridge: {rmse_ridge:.5f}")
print(f"RÂ² Ridge:   {r2_ridge:.5f}")


# --- 2.2 LASSO REGRESSION (L1) ---
print("\n--- LASSO REGRESSION (SeleÃ§Ã£o de VariÃ¡veis) ---")

# O Lasso zera coeficientes. Vamos ver se ele joga fora alguma variÃ¡vel quimica.
lasso_model = LassoCV(cv=5, random_state=42, max_iter=10000)
lasso_model.fit(x_train_ajusted_norm, y_train)

y_pred_lasso = lasso_model.predict(x_test_ajusted_norm)

rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))
r2_lasso = r2_score(y_test, y_pred_lasso)

print(f"Melhor Alpha Lasso: {lasso_model.alpha_:.6f}")
print(f"RMSE Lasso: {rmse_lasso:.5f}")
print(f"RÂ² Lasso:   {r2_lasso:.5f}")

# --- 2.3 ANÃLISE DO LASSO (O que foi zerado?) ---
print("\n>>> VariÃ¡veis eliminadas pelo Lasso:")
# Pegamos os nomes das colunas originais
colunas_originais = x_database.columns
coeficientes = pd.Series(lasso_model.coef_, index=colunas_originais)

# Mostra quem foi zerado
zerados = coeficientes[coeficientes == 0]
if len(zerados) > 0:
    print(f"O Lasso zerou {len(zerados)} variÃ¡veis: {list(zerados.index)}")
    print("Isso indica que essas variÃ¡veis podem ser irrelevantes para a qualidade.")
else:
    print("Nenhuma variÃ¡vel foi zerada (Todas sÃ£o importantes).")

print("\n" + "="*80)

# ================================================================================================================================
# ETAPA 4: REDE NEURAL (MLP)
# ================================================================================================================================

from sklearn.neural_network import MLPRegressor

print("\n" + "="*80)
print("INICIANDO ETAPA 4: REDE NEURAL (MLP Regressor)")
print("="*80)

# ConfiguraÃ§Ã£o da Rede Neural (Perceptron Multicamadas)
# Escolhas dos parÃ¢metros:
# 1. hidden_layer_sizes=(100,): Uma camada oculta com 100 neurÃ´nios. Ã‰ um bom ponto de partida pra esse tamanho de dataset.
# 2. activation='relu': PadrÃ£o ouro pra regressÃ£o, funciona melhor que sigmoide pra evitar gradiente sumindo.
# 3. solver='adam': Otimizador eficiente pra datasets desse tamanho (alguns milhares de linhas).
# 4. max_iter=5000: Botei alto de propÃ³sito. O padrÃ£o (200) as vezes nÃ£o Ã© suficiente pra convergir e fica dando warning chato.
# 5. random_state=42: Pra garantir que se rodar de novo, dÃ¡ o mesmo resultado.

mlp_model = MLPRegressor(hidden_layer_sizes=(100,), 
                         activation='relu', 
                         solver='adam', 
                         max_iter=5000, 
                         random_state=42)

# Treinamento
# 'x_train_ajusted_norm' jÃ¡ foi tratado com Z-Score lÃ¡ em cima.
print("Treinando a rede neural...")
mlp_model.fit(x_train_ajusted_norm, y_train)

# PrevisÃ£o no conjunto de teste
y_pred_mlp = mlp_model.predict(x_test_ajusted_norm)

# CÃ¡lculo das mÃ©tricas finais
rmse_mlp = np.sqrt(mean_squared_error(y_test, y_pred_mlp))
r2_mlp = r2_score(y_test, y_pred_mlp)

print(f"RMSE Rede Neural: {rmse_mlp:.5f}")
print(f"RÂ² Rede Neural:   {r2_mlp:.5f}")

# Pequena lÃ³gica pra responder a pergunta do PDF sobre "Nonlinear vs Linear"
print("\n>>> Veredito: Rede Neural vs Linear (OLS/Lasso)")
if r2_mlp > r2_test: # r2_test Ã© o do OLS/PCR que calculamos antes
    print("A Rede Neural superou o modelo linear. Isso sugere que existem relaÃ§Ãµes nÃ£o-lineares nos dados quÃ­micos.")
else:
    print("A Rede Neural NÃƒO superou significativamente o linear. O problema parece ser predominantemente linear ou ter muito ruÃ­do.")
print("="*80)