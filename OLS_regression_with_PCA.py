# Primeiro an√°lise e pr√© processamento, aplica√ß√£o de PCA para redu√ß√£o de dimensionalidade e ent√£o aplica√ß√£o do modelo
# Na primeira rodagem s√≥ se faz o modelo simples separando treino e teste usualmente (2/3 e 1/3)
# Separados em Treino e Teste, por√©m como vamos aplicar Cross validation, vamos dividir os K-folds logo, igualmente (5 a 10)
# Vamos fazer com 10 folders, o treino √© feito com todos os folds, exceto o que virou teste na rodada
# Treino: [F1 F2 F3 F6] Teste: [F5],Treino: [F2 F3 F5 F6] Teste: [F1]...
# ‚úÖ Para setores terminados e ‚ùå para incompletos


import pandas as pd
import numpy as np
from scipy.stats import boxcox
from sklearn.decomposition import PCA



# ‚úÖ Carregamento do csv  =============================
database = pd.read_csv("winequality-red.csv", sep=";")
#print(database.columns)
#print(len(database))
print("\nDimens√µes do conjunto completo: ",database.shape) 
#=====================================================



# ‚úÖ Shuffle pra embaralhar as entradas ================================================================
ind_shuffle = np.random.permutation(len(database))              #cria os indicies
database = database.iloc[ind_shuffle].reset_index(drop=True)    #embaralha e reseta a posicao do indice
#=======================================================================================================



# ‚úÖ Separa√ß√£o de features e target ===========
x_database = database.drop(columns=["quality"])
y_database = database["quality"]
#==============================================



# ‚úÖ= C√°lculo do Skewness pra ajeitar =
skew = x_database.skew()
#print(skew)
#=====================================



# ‚úÖ Separa√ß√£o de treino e teste ========================================================================
n = int(np.floor(len(database)/3))   #um ter√ßo do tamanho arredondado pra baixo
data_train = database[:2*n]
data_test = database[2*n:]
#print("Tamanho do conjunto de treino: ",len(data_train),"Tamanho do conjunto de teste :",len(data_test))
#========================================================================================================



# ‚úÖ Separa√ß√£o de features e target de treino e teste ==
y_train = y_database[:2*n]
x_train = x_database[:2*n]
print("\nDimens√µes dos preditores de treino: ",x_train.shape) 
y_test = y_database[2*n:]
x_test = x_database[2*n:]
print("\nDimens√µes dos preditores de teste: ",x_test.shape)
#======================================================


# ------------> ADICIONAR UM VIOLIN PLOT ANTES E DEPOIS <------------- 

# ‚úÖ Ajuste para diminuir o skewness com Box-Cox ===================================================================================================
#GARANTIR QUE USE O BOXCOX NO TREINO, GUARDE OS LAMBDAS E APLIQUE ELES NO TESTE, FAZER TUDO JUNTO PODE VAZAR TENDENCIA DO 
# TREINO PRO TESTE ATRAVES DO PARAMETRO LAMBDA DE ACORDO COM A DISTRIBUI√á√ÉO DOS DADOS, J√Å √â UM MODELO ESTATISTICO TREINADO
#  E NAO PODE SABER DA DISTRIBUI√á√ÉO DO CONJUNTO DE TESTES.
x_train_ajusted = x_train.copy()
lambdas = {}    # para aplicar no teste depois os mesmos lambdas no boxcox
shifts = {}     # para aplicar no teste depois os shifts no canto correto
for col in x_train_ajusted.columns:
    val = x_train_ajusted[col].values
    # Box-Cox precisa de valores > 0
    if np.any(val <= 0):                  # se tiver um valor negativo, ajeita pra positivo
        shift = abs(np.min(val)) + 1e-6   # calculo do shift para avan√ßar todos os valores negativos e 0, maiores que 0
        val = val + shift                 # deslocamento necessario pra ficar positivo se tiver algum valor menor que zero nos valores da coluna
        shifts[col] = shift
    else:
        shifts[col] = 0.0

    transf_val, boxcox_lambdas = boxcox(val)    # salva os lambdas pra poder usar no conjunto de teste mais tarde e os valores transformados
    x_train_ajusted[col] = transf_val           # monta denovo o a matriz
    lambdas[col] = boxcox_lambdas               # grava os lambdas
# print("\nNovos skewness p√≥s box-cox do conjunto de treino\n",x_train_ajusted.skew())
# para setar um lambda mais afrente no conjunto de teste usaremos transf_val = boxcox(val[col], lmbda=lambdas[col])
#==================================================================================================================================================



# ‚úÖ (Z-SCORE) Inicio da aplica√ß√£o do PCA para redu√ß√£o da dimensionalidade ======================================================
# Normaliza√ß√£o m√©dia 0 e desvio padrao 1 para realizar o calculo correto da matriz de covari√¢ncia.
mean_train = np.mean(x_train_ajusted, axis=0)
std_train = np.std(x_train_ajusted, axis=0)
x_train_ajusted_norm = (x_train_ajusted - mean_train) / std_train   #Padroniza√ß√£o Z-score com a media e o desvio padrao.
# print (x_train_ajusted_norm)
# IMPORTANTE USAR OS VALORES DO MODELO DE TREINO DE STD E MEAN PARA O CONJUNTO DE TESTE QUANDO FOR FAZER O Z-SCORE DENOVO E O PCA.
#===============================================================================================================================



# ‚úÖ Calculo do PCA nativo =====================================================================================================
# Com o calculo nativo nao precisamos passar a matriz de covari√¢ncia, apenas os dados, ele calcular√° da mesma forma e far√° a
# mesma checagem de posto.
pca = PCA()
pca.fit(x_train_ajusted_norm)           # PCA completo pra retorno de todos os PCS e 
print ("\n \nVari√¢ncia explicada por componente principal", pca.explained_variance_ratio_.cumsum(),"\n\n")    # vari√¢ncia explicada cumulativa
# Escolha de 9 features para 97% de vari√¢ncia explicada aceitavel
n_pcs = 9
pca_reduzido = PCA(n_components=n_pcs)      # Determina√ß√£o do PCA com retorno s√≥ dos 9 primeiros PC's
pca_reduzido.fit(x_train_ajusted_norm)  # C√°lculo efetivo do PCA no conjunto com 9 PC's

x_train_pca = pca_reduzido.transform(x_train_ajusted_norm)          # Trasnforma√ß√£o do conjunto com os PC's escolhidos
print("\n Dimensionalidade de treino trasnf.: ",x_train_pca.shape)  # Dimensionalidade esperada: 1066(amostras de treino) x 9(PC's)
#================================================================================================================================


#=============================================üéØ INICIO DA FASE DE TREINO üéØ====================================================
# ‚úÖ Regress√£o multivariada via M√≠nimos quadrados (OLS) =========================================================================
# Y = b0 + b1x1 + b2x2 ... + bnxn + e , sendo x cada uma das features
# ou seja temos 9 + 1 colunas, contando com o b0, adicionamos entao essa coluna
x_train_pca_bias = np.column_stack([np.ones(x_train_pca.shape[0]), x_train_pca])  #adiciona uma coluna de 1's para representar o b0

# aplica√ß√£o da f√≥rmula do OLS [(Xt*X)^-1 * Xt * Y]
betas = np.linalg.inv(  x_train_pca_bias.T     @       x_train_pca_bias )     @       (x_train_pca_bias.T    @   y_train)
print("Betas resultantes: ",betas)      # Esperados 10 betas

# c√°lculo do erro m√©dio quadrado (RMSE) de valida√ß√£o no treino sqrt(   mean( (Y - Ypred)^2 )  )
y_predict_train =  x_train_pca_bias @ betas
MSE_train = np.sqrt(np.mean((y_train - y_predict_train)**2))
print("\nRMSE de treino:", MSE_train)

# C√°lculo do R^2
y_mean_train = np.mean(y_train)
r2_train = 1 - np.sum((y_train - y_predict_train)**2) / np.sum((y_train - y_mean_train)**2) #o sum vai somar os numeradores entre si e os denominadores
print("\nR2 de treino:", r2_train)

#[np.linalg.inv: √© a inversa no python]
#[      @      : √© o multiplicador matricial do python]
#=================================================================================================================================



#=============================================üß™ INICIO DA FASE DE TESTES üß™=====================================================
# ‚úÖ Adapta√ß√£o do conjunto de testes e aplica√ß√£o do modelo =======================================================================
# Aplicando todas as trasnforma√ß√µes no conjunto de testes denovo com os todos os parametros obtidos do TREINO (media, dp, lambdas, 
# PCA, shifts e betas)

#boxcox com lambdas salvos
x_test_ajusted = x_test.copy()
for i in range(x_test.shape[1]):
    col = x_test.columns[i]
    val_test = x_test_ajusted.values[:,i] + shifts[col]                   #soma os shifts iguais aos do treino
    x_test_ajusted[col] = boxcox(val_test, lmbda=lambdas[col])  #aplica o boxcox com os lambdas iguais aos do treino
    # Utilizar o mesmo shift que no treino pra nao dar data-leakage, checar se nao 
    # fica nada negativo, caso fique aumentar a parcela de soma fixa do shift no treino
    
# Z-score com mean e std salvos
x_test_ajusted_norm = (x_test_ajusted - mean_train) / std_train     #os mesmos do treino pra evitar o leakage

# PCA (aplica a mesma matriz do treino, apenas transforma os dados direto)
x_test_pca = pca_reduzido.transform(x_test_ajusted_norm)

# Bias (nada muda)
x_test_pca = np.column_stack([np.ones(x_test_pca.shape[0]), x_test_pca])

# Aplica√ß√£o do modelo para valida√ß√£o e (MSE) de valida√ß√£o no teste
y_predict_test = x_test_pca @ betas
MSE_test = np.sqrt(np.mean((y_test - y_predict_test)**2))
print("\nRMSE de teste :", MSE_test)

#(R2)
y_mean_test = np.mean(y_test)
r2_test = 1 - np.sum((y_test - y_predict_test)**2) / np.sum((y_test - y_mean_test)**2)
print("\nR2 de teste:", r2_test)

#Sobre as estat√≠sticas
#Treino baixo + Teste baixo -> ‚úÖ BOM
#Treino baixo + Teste alto  -> ‚ùå OVERFITTING
#Treino alto + Teste alto   -> ‚ùå UNDERFITTING
#Treino alto + Teste baixo  -> (erro no c√≥digo)
#Modelo atual puxa sempre pro "Meio", nao tem complexidade suficiente pra se adequar as nao liearidades dos dados.
#=================================================================================================================================


# COMPARACAO MANUAL DAS PREDI√á√ïES
#comparacao = pd.DataFrame({
#    "y_real": y_test.values[:10].flatten(),
#    "y_pred": y_predict_test[:10].flatten()
#})
#print(comparacao)


#modelo pra implementa√ß√£o futura

#=============================== K-fold implementation ============================
#from sklearn.model_selection import KFold
#
#kf = KFold(n_splits=5, shuffle=True, random_state=42)
#
#for train_idx, test_idx in kf.split(X):
#    X_train, X_test = X[train_idx], X[test_idx]
#    y_train, y_test = y[train_idx], y[test_idx]
#
#    # treina o modelo
#==================================================================================